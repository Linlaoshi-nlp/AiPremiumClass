{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现基于豆瓣top250图书评论的简单推荐系统（TF-IDF及BM25两种算法实现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import os.path as os\n",
    "import csv\n",
    "import jieba\n",
    "from bm25_code import bm25\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、文件清洗（换行问题&空评论）\n",
    "def get_format_file(oldFile, newFile):\n",
    "    # 目标文件\n",
    "    new_f = open(newFile, 'w')  \n",
    "    with open(oldFile, 'r') as f:\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            # 标题行处理\n",
    "            if i == 0:\n",
    "                new_f.write(line + \"\\n\")\n",
    "                pre_line = ''\n",
    "                continue\n",
    "            # 换行问题\n",
    "            if line.split(\"\\t\")[0] == pre_line.split(\"\\t\")[0]:\n",
    "                new_f.write(pre_line + \"\\n\")\n",
    "                pre_line = line\n",
    "            else:\n",
    "                # 新书 or 评论换行\n",
    "                if len(line.split(\"\\t\")) == 6:\n",
    "                    # 新书\n",
    "                    if pre_line.strip() != '':\n",
    "                        new_f.write(pre_line + \"\\n\")                \n",
    "                    pre_line = line\n",
    "                else:\n",
    "                    # 评论换行\n",
    "                    pre_line += line\n",
    "    new_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、文件分词\n",
    "def split_file_comments(fileName):\n",
    "    book_comments = {}\n",
    "    with open(fileName, 'r') as f:\n",
    "        # csv首行作为字典键\n",
    "        lines = csv.DictReader(f, delimiter='\\t')\n",
    "        for line in lines:\n",
    "            book_name = line.get('book', '')\n",
    "            book_comment = line.get('body', '')\n",
    "            \n",
    "            if not book_name or not book_comment:\n",
    "                continue\n",
    "            \n",
    "            # 分词\n",
    "            comments_words = jieba.lcut(book_comment)\n",
    "            \n",
    "            book_comments.setdefault(book_name, []).extend(comments_words)\n",
    "\n",
    "    \n",
    "    return book_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3、模型训练\n",
    "def comments_vectors_similarity(comments, method, stop_words):\n",
    "    if method == 'bm25':\n",
    "        matrix = bm25(comments, stop_words=stop_words)\n",
    "    if method == 'tfidf':\n",
    "        tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "        matrix = tfidf.fit_transform([\" \".join(comment) for comment in comments])\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    similarity_matrix = cosine_similarity(matrix)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\uchonor\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.362 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "d:\\dyySoftWare\\newsoftware\\envs\\py312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'aren', 'couldn', 'daren', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mayn', 'mightn', 'mon', 'mustn', 'needn', 'oughtn', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF算法推荐的图书：\n",
      "\n",
      "《三体》 \t 相似度：0.2185\n",
      "《人类简史》 \t 相似度：0.1930\n",
      "《拆掉思维里的墙》 \t 相似度：0.1889\n",
      "《遇见未知的自己》 \t 相似度：0.1819\n",
      "《少有人走的路》 \t 相似度：0.1770\n",
      "《皮囊》 \t 相似度：0.1720\n",
      "《三体Ⅲ》 \t 相似度：0.1641\n",
      "《时间旅行者的妻子》 \t 相似度：0.1591\n",
      "《球状闪电》 \t 相似度：0.1562\n",
      "《穆斯林的葬礼》 \t 相似度：0.1554\n",
      "\n",
      "BM25算法推荐的图书：\n",
      "\n",
      "《麦田里的守望者》 \t 相似度：0.1044\n",
      "《梦里花落知多少》 \t 相似度：0.1004\n",
      "《一个人的朝圣》 \t 相似度：0.0953\n",
      "《原来你还在这里》 \t 相似度：0.0911\n",
      "《何以笙箫默》 \t 相似度：0.0911\n",
      "《致我们终将逝去的青春》 \t 相似度：0.0894\n",
      "《那些回不去的年少时光》 \t 相似度：0.0892\n",
      "《莲花》 \t 相似度：0.0861\n",
      "《山楂树之恋》 \t 相似度：0.0833\n",
      "《平凡的世界（全三部）》 \t 相似度：0.0829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 1、文件清洗\n",
    "    newFile = 'hw1_doubanbook_top250_comments.txt'\n",
    "    oldFile = 'doubanbook_top250_comments.txt'\n",
    "    if(not os.exists(newFile)):\n",
    "        get_format_file(oldFile, newFile)\n",
    "    \n",
    "    # 2、文件分词\n",
    "    book_comments = split_file_comments(newFile)\n",
    "    \n",
    "    # 3、模型训练\n",
    "    book_name = []\n",
    "    book_comment = []\n",
    "    for name, comment in book_comments.items():\n",
    "        book_name.append(name)\n",
    "        book_comment.append(comment)\n",
    "        \n",
    "    stop_words = [line.strip() for line in open(\"stopwords.txt\", \"r\", encoding=\"utf-8\")]\n",
    "    \n",
    "    # TF-IDF算法得到的相似度矩阵\n",
    "    tfidf_matrix = comments_vectors_similarity(book_comment, 'tfidf', stop_words)\n",
    "    # BM25算法得到的相似度矩阵\n",
    "    bm25_matrix = comments_vectors_similarity(book_comment, 'bm25', stop_words)\n",
    "    \n",
    "    # 4、推荐书籍\n",
    "    in_book_name = '天才在左 疯子在右'\n",
    "    \n",
    "    book_list = list(book_comments.keys())\n",
    "    in_book_idex = book_list.index(in_book_name)\n",
    "    \n",
    "    print(f\"TF-IDF算法推荐的图书：\\n\")\n",
    "    recommend_book_index = np.argsort(-tfidf_matrix[in_book_idex])[1:11]\n",
    "    for idx in recommend_book_index:\n",
    "        print(f\"《{book_name[idx]}》 \\t 相似度：{tfidf_matrix[in_book_idex][idx]:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"BM25算法推荐的图书：\\n\")\n",
    "    recommend_book_index = np.argsort(-bm25_matrix[in_book_idex])[1:11]\n",
    "    for idx in recommend_book_index:\n",
    "        print(f\"《{book_name[idx]}》 \\t 相似度：{bm25_matrix[in_book_idex][idx]:.4f}\")\n",
    "    print()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验使用不同的RNN结构，实现一个人脸图像分类器。\n",
    "# 至少对比2种以上结构训练损失和准确率差异，如：LSTM、GRU、RNN、BiRNN等。要求使用tensorboard，\n",
    "# 提交代码及run目录和可视化截图。\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from model.rnn_model import RNN\n",
    "from model.lstm_model import LSTM\n",
    "from model.gru_model import GRU\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数定义\n",
    "BATCH_SIZE = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、数据集加载\n",
    "images, label = fetch_olivetti_faces(data_home='./face_data', shuffle=True, return_X_y=True)\n",
    "\n",
    "X = images.reshape(-1, 64, 64)  # (400, 64, 64)\n",
    "y = label #(400,)\n",
    "# 2、拆分测试集 (每个批次中的样本数量, 每个样本中时间步的数量, 每个时间步的特征数量)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "# 3、数据集转tensor (unsqueeze在1维添加一个维度) \n",
    "# X（320,4096）->(320,1,4096) Y（320,）->(320)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# 4、捆绑输入数据和对应的标签\n",
    "train_datasets = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_datasets = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# 5、分批次\n",
    "train_loader = DataLoader(train_datasets, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_datasets, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train_model(model, writer, model_name):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0 # 总损失值\n",
    "        for X,y in train_loader:\n",
    "            y_hat = model(X)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        avg_loss = train_loss / len(train_loader) # 当前批次平均损失\n",
    "        writer.add_scalar(f'{model_name}/Train Loss', avg_loss, epoch)\n",
    "        print(f\"epoch: {epoch}, loss: {avg_loss}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试验证函数\n",
    "def test_train(model):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, label in test_loader:\n",
    "            y_hat = model(images)\n",
    "            _, max_idx = torch.max(y_hat, dim=1)\n",
    "            total += label.size(0)\n",
    "            correct += (max_idx == label).sum().item()\n",
    "        print(f\"total: {total}, correct: {correct}\")\n",
    "    return correct/total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN...\n",
      "epoch: 0, loss: 3.708177328109741\n",
      "epoch: 1, loss: 3.5733075857162477\n",
      "epoch: 2, loss: 3.3024811029434202\n",
      "epoch: 3, loss: 3.0858227968215943\n",
      "epoch: 4, loss: 2.9007876396179197\n",
      "epoch: 5, loss: 2.678826355934143\n",
      "epoch: 6, loss: 2.5816395759582518\n",
      "epoch: 7, loss: 2.4255423545837402\n",
      "epoch: 8, loss: 2.343341255187988\n",
      "epoch: 9, loss: 2.209446680545807\n",
      "epoch: 10, loss: 2.12331737279892\n",
      "epoch: 11, loss: 2.0209432244300842\n",
      "epoch: 12, loss: 1.9134453296661378\n",
      "epoch: 13, loss: 1.8719324707984923\n",
      "epoch: 14, loss: 1.8357917547225953\n",
      "epoch: 15, loss: 1.8679407000541688\n",
      "epoch: 16, loss: 1.8161273837089538\n",
      "epoch: 17, loss: 1.7131071090698242\n",
      "epoch: 18, loss: 1.6755007028579711\n",
      "epoch: 19, loss: 1.7315719962120055\n",
      "epoch: 20, loss: 1.552405846118927\n",
      "epoch: 21, loss: 1.4836797952651977\n",
      "epoch: 22, loss: 1.4075274348258973\n",
      "epoch: 23, loss: 1.452639353275299\n",
      "epoch: 24, loss: 1.329300320148468\n",
      "epoch: 25, loss: 1.3174033164978027\n",
      "epoch: 26, loss: 1.2849681615829467\n",
      "epoch: 27, loss: 1.2346946358680726\n",
      "epoch: 28, loss: 1.1888554334640502\n",
      "epoch: 29, loss: 1.1916259169578551\n",
      "total: 80, correct: 29\n",
      "RNN Test Accuracy: 36.25%\n",
      "Training LSTM...\n",
      "epoch: 0, loss: 3.6912800550460814\n",
      "epoch: 1, loss: 3.660581660270691\n",
      "epoch: 2, loss: 3.4917885780334474\n",
      "epoch: 3, loss: 3.290070915222168\n",
      "epoch: 4, loss: 3.01304292678833\n",
      "epoch: 5, loss: 2.820025181770325\n",
      "epoch: 6, loss: 2.7105891704559326\n",
      "epoch: 7, loss: 2.511712741851807\n",
      "epoch: 8, loss: 2.376714587211609\n",
      "epoch: 9, loss: 2.2215973854064943\n",
      "epoch: 10, loss: 2.132211458683014\n",
      "epoch: 11, loss: 2.0523072242736817\n",
      "epoch: 12, loss: 1.9143067955970765\n",
      "epoch: 13, loss: 1.7346124410629273\n",
      "epoch: 14, loss: 1.6412119150161744\n",
      "epoch: 15, loss: 1.668095016479492\n",
      "epoch: 16, loss: 1.4803609013557435\n",
      "epoch: 17, loss: 1.4289173007011413\n",
      "epoch: 18, loss: 1.3260836958885194\n",
      "epoch: 19, loss: 1.3915300607681274\n",
      "epoch: 20, loss: 1.2240508913993835\n",
      "epoch: 21, loss: 1.1231707692146302\n",
      "epoch: 22, loss: 1.0902788996696473\n",
      "epoch: 23, loss: 1.078176873922348\n",
      "epoch: 24, loss: 1.0803149461746215\n",
      "epoch: 25, loss: 1.1622014880180358\n",
      "epoch: 26, loss: 0.9164227962493896\n",
      "epoch: 27, loss: 0.8441033124923706\n",
      "epoch: 28, loss: 0.8232703447341919\n",
      "epoch: 29, loss: 0.752228045463562\n",
      "total: 80, correct: 46\n",
      "LSTM Test Accuracy: 57.49999999999999%\n",
      "Training GRU...\n",
      "epoch: 0, loss: 3.7076652526855467\n",
      "epoch: 1, loss: 3.6413307428359984\n",
      "epoch: 2, loss: 3.5709511041641235\n",
      "epoch: 3, loss: 3.359226608276367\n",
      "epoch: 4, loss: 3.026134181022644\n",
      "epoch: 5, loss: 2.74504075050354\n",
      "epoch: 6, loss: 2.53509783744812\n",
      "epoch: 7, loss: 2.386449766159058\n",
      "epoch: 8, loss: 2.2577521085739134\n",
      "epoch: 9, loss: 2.1692425489425657\n",
      "epoch: 10, loss: 1.982308554649353\n",
      "epoch: 11, loss: 1.9175837755203247\n",
      "epoch: 12, loss: 1.773608183860779\n",
      "epoch: 13, loss: 1.6650493502616883\n",
      "epoch: 14, loss: 1.6458080291748047\n",
      "epoch: 15, loss: 1.5489395022392274\n",
      "epoch: 16, loss: 1.5247506260871888\n",
      "epoch: 17, loss: 1.412945067882538\n",
      "epoch: 18, loss: 1.3360194921493531\n",
      "epoch: 19, loss: 1.2677339673042298\n",
      "epoch: 20, loss: 1.3206775903701782\n",
      "epoch: 21, loss: 1.1697687566280366\n",
      "epoch: 22, loss: 1.1231517910957336\n",
      "epoch: 23, loss: 1.051488983631134\n",
      "epoch: 24, loss: 0.9811523973941803\n",
      "epoch: 25, loss: 0.9108342111110688\n",
      "epoch: 26, loss: 0.8650757312774658\n",
      "epoch: 27, loss: 0.8139694511890412\n",
      "epoch: 28, loss: 0.7865675926208496\n",
      "epoch: 29, loss: 0.7504435300827026\n",
      "total: 80, correct: 37\n",
      "GRU Test Accuracy: 46.25%\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "models = {\n",
    "    \"RNN\": RNN(),\n",
    "    'LSTM': LSTM(),\n",
    "    'GRU': GRU()\n",
    "}\n",
    "\n",
    "writer = SummaryWriter('runs/face_classfier')\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    train_loss = train_model(model, writer, model_name)\n",
    "    accuracy = test_train(model)\n",
    "    writer.add_scalar(f'{model_name}/Test Accuracy', accuracy, 0)\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy}%\")\n",
    "    \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

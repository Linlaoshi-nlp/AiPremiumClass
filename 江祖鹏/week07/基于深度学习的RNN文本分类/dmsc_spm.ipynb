{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入外部文件训练训练分词模型\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input = 'XYJ.txt',\n",
    "    model_prefix = \"XYJ_mod\",\n",
    "    vocab_size=10000, \n",
    "    model_type='unigram',      # 或 'bpe'\n",
    "    user_defined_symbols=['PAD','UNK']  # 自定义符号（可选）\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('XYJ_mod.model')\n",
    "\n",
    "ds_comments = []\n",
    "with open('C','r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        star = int(row['Star'])\n",
    "        if star in [1,2,4,5]:\n",
    "            comment = row[\"Comment\"]\n",
    "            #使用 EncodeAsIds 直接得到 ID\n",
    "            words = sp.EncodeAsIds(comment)\n",
    "            ds_comments.append((words, 1 if star > 2 else 0))\n",
    "\n",
    "print(len(ds_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_comments = [c for c in ds_comments if len(c[0]) in range(10, 150)]\n",
    "print(len(ds_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ds_comments.pkl','rb') as f:\n",
    "        comments_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Comments_Classifier(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_size,num_classes,pad_id=0): \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_id)\n",
    "        self.rnn = nn.LSTM(embedding_dim,hidden_size,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # input_ids: (batch_size, seq_len)\n",
    "        # embedded: (batch_size, seq_len, embedding_dim)\n",
    "        embedded = self.embedding(input_ids)\n",
    "        # output: (batch_size, seq_len, hidden_size)\n",
    "        output, (hidden, _) = self.rnn(embedded)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        \n",
    "        return output\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #设备配置\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #加载训练语料\n",
    "    with open('ds_comments.pkl','rb') as f:\n",
    "        comments_data = pickle.load(f)\n",
    "\n",
    "    #构建词汇表\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.Load('XYJ_mod.model')\n",
    "    vocab_size = sp.GetPieceSize()# 直接获取词汇表大小\n",
    "\n",
    "    #所有向量集合 Embedding（词嵌入）\n",
    "    # emb = nn.Embedding(len(w2idx),100) # 词汇表大小，向量维度\n",
    "\n",
    "    #回调函数，自定义数据转换方法\n",
    "    #该函数会在每个batch数据加载时被调用\n",
    "    def convert_data(batch_data):\n",
    "        comments, votes = [],[]\n",
    "        #分别提取评论和标签\n",
    "        for comment,vote in batch_data:\n",
    "            comments.append(torch.tensor( comment))\n",
    "            votes.append(vote)\n",
    "\n",
    "        #将评论和标签转换为tensor,# 使用 SentencePiece 的 pad_id\n",
    "        commt = pad_sequence(comments, batch_first=True, padding_value=sp.pad_id())\n",
    "        lables = torch.tensor(votes)\n",
    "        return commt, lables\n",
    "    #通过Dataset构建DataLoader\n",
    "    dataloader = DataLoader(comments_data, batch_size=32, shuffle=True, collate_fn=convert_data)\n",
    "\n",
    "\n",
    "    #模型参数\n",
    "    vocab_size = vocab_size\n",
    "    embedding_dim = 100\n",
    "    hidden_size = 128\n",
    "    num_classes = 2\n",
    "\n",
    "    #构建模型\n",
    "    model = Comments_Classifier(vocab_size, embedding_dim, hidden_size, num_classes).to(device)\n",
    "\n",
    "    #损失函数\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    #训练模型\n",
    "    num_epochs = 1\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (comm,lable) in enumerate(dataloader):\n",
    "            #将数据移动到设备上\n",
    "            comm = comm.to(device)\n",
    "            lable = lable.to(device)\n",
    "\n",
    "            #前向传播\n",
    "            outputs = model(comm)\n",
    "            #计算损失\n",
    "            loss = criterion(outputs, lable)\n",
    "            #反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            #更新参数\n",
    "            optimizer.step()\n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch[{epoch+1}/{num_epochs}],step[{i+1}/{len(dataloader)}],loss:{loss.item():.4f}')\n",
    "\n",
    "\n",
    "        #保存模型\n",
    "    torch.save(model.state_dict(),'dmsc_comments_classifier_spm.pth')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型推理\n",
    "\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_size = 128\n",
    "num_classes = 2\n",
    "\n",
    "#加载模型\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('XYJ_mod.model')\n",
    "vocab_size = sp.GetPieceSize()# 直接获取词汇表大小\n",
    "\n",
    "# 测试模型\n",
    "comment1 = '这部电影真好看！我很喜欢'\n",
    "comment2 = '看到一半就不想看了，太无聊了，演员演技也很差'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 文本预处理函数（使用 SentencePiece 编码）\n",
    "def text_to_tensor(text, sp_model, device):\n",
    "    ids = sp_model.EncodeAsIds(text)  # 直接生成 ID 列表\n",
    "    return torch.tensor([ids], dtype=torch.long).to(device)\n",
    "\n",
    "# 将评论转换为索引\n",
    "comment1_idx = text_to_tensor(comment1, sp, device)\n",
    "comment2_idx = text_to_tensor(comment2, sp, device)\n",
    "\n",
    "#加载模型\n",
    "model = Comments_Classifier(vocab_size, embedding_dim, hidden_size, num_classes, sp.pad_id())\n",
    "model.load_state_dict(torch.load('dmsc_comments_classifier_spm.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "#模型推理\n",
    "with torch.no_gard():\n",
    "    pred1 = model(comment1_idx)\n",
    "    pred2 = model(comment2_idx)\n",
    "\n",
    "# 取最大值的索引作为预测结果\n",
    "with torch.no_grad():\n",
    "    pred1 = torch.argmax(pred1, dim=1).item()\n",
    "    pred2 = torch.argmax(pred2, dim=1).item()\n",
    "\n",
    "print(f'评论1的预测结果: {pred1}')\n",
    "print(f'评论2的预测结果: {pred2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

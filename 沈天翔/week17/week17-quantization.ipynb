{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:35:11.894630Z","iopub.execute_input":"2025-07-24T15:35:11.895195Z","iopub.status.idle":"2025-07-24T15:35:12.173114Z","shell.execute_reply.started":"2025-07-24T15:35:11.895158Z","shell.execute_reply":"2025-07-24T15:35:12.172458Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -q bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:35:12.174337Z","iopub.execute_input":"2025-07-24T15:35:12.175093Z","iopub.status.idle":"2025-07-24T15:36:42.469024Z","shell.execute_reply.started":"2025-07-24T15:35:12.175073Z","shell.execute_reply":"2025-07-24T15:36:42.467960Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\n\n# 模型名称\nmodel_name = \"Qwen/Qwen1.5-7B-Chat\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:36:42.470176Z","iopub.execute_input":"2025-07-24T15:36:42.470488Z","iopub.status.idle":"2025-07-24T15:36:53.762357Z","shell.execute_reply.started":"2025-07-24T15:36:42.470460Z","shell.execute_reply":"2025-07-24T15:36:53.761723Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# 配置4-bit量化\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,                  # 启用4-bit量化\n    bnb_4bit_compute_dtype=torch.float16,  # 计算时用float16加速\n    bnb_4bit_quant_type=\"nf4\",          # 量化类型（推荐nf4）\n    bnb_4bit_use_double_quant=True,     # 二次量化进一步压缩\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:36:53.763796Z","iopub.execute_input":"2025-07-24T15:36:53.764183Z","iopub.status.idle":"2025-07-24T15:36:53.769139Z","shell.execute_reply.started":"2025-07-24T15:36:53.764164Z","shell.execute_reply":"2025-07-24T15:36:53.768492Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 加载tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    trust_remote_code=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:36:53.769869Z","iopub.execute_input":"2025-07-24T15:36:53.770218Z","iopub.status.idle":"2025-07-24T15:36:54.947672Z","shell.execute_reply.started":"2025-07-24T15:36:53.770188Z","shell.execute_reply":"2025-07-24T15:36:54.947052Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be45f60cd4d7442bb78ca8e44b32c39c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c1398815a7946f79b7a2c036d295fe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"421e9fd34c0e447a9ae7643b28fe41c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff640336ba1b4b6fa53b367bab4879cd"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",                 # 自动分配 GPU/CPU\n    quantization_config=quantization_config,\n    trust_remote_code=True,\n    torch_dtype=torch.float16,         # 显存优化\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:36:54.948739Z","iopub.execute_input":"2025-07-24T15:36:54.948997Z","iopub.status.idle":"2025-07-24T15:40:30.075529Z","shell.execute_reply.started":"2025-07-24T15:36:54.948978Z","shell.execute_reply":"2025-07-24T15:40:30.074682Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cebd5e36776041469139d5d81d2d7a26"}},"metadata":{}},{"name":"stderr","text":"2025-07-24 15:37:03.964962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753371424.324639      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753371424.432764      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d9018d4e26b474190edd8e0e48c2b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40cfbf0f4dc04d1682613a6544909cd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abc305a28321443fb87414d93fdfe5c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdc59d5dcde04483b19efc501251bd37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c3663726c454294b3392d2e77796078"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bafb9eac74e441af8193c2b0ba6d620c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"237d5c0139b140b59578922d9e51ad48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4574d3a03ab849dc9a231fd753caceff"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# 推理函数（支持多轮对话）\ndef generate_response(prompt, max_new_tokens=200):\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=max_new_tokens,\n        do_sample=True,\n        temperature=0.7,              # 控制随机性（0~1）\n        top_p=0.9,                     # 核采样（0~1）\n    )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:40:30.076445Z","iopub.execute_input":"2025-07-24T15:40:30.077071Z","iopub.status.idle":"2025-07-24T15:40:30.083702Z","shell.execute_reply.started":"2025-07-24T15:40:30.077050Z","shell.execute_reply":"2025-07-24T15:40:30.083080Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# 测试对话\nprompt = \"你好，请用Python写一个快速排序算法。\"\nresponse = generate_response(prompt, 500)\nprint(\"模型回答：\\n\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T15:41:19.818755Z","iopub.execute_input":"2025-07-24T15:41:19.819171Z","iopub.status.idle":"2025-07-24T15:41:53.145952Z","shell.execute_reply.started":"2025-07-24T15:41:19.819139Z","shell.execute_reply":"2025-07-24T15:41:53.145170Z"}},"outputs":[{"name":"stdout","text":"模型回答：\n 你好，请用Python写一个快速排序算法。 当然，以下是使用Python实现的快速排序算法：\n\n```python\ndef quick_sort(arr):\n    if len(arr) <= 1:\n        # 如果数组只有一个元素或为空，直接返回\n        return arr\n    else:\n        # 选择一个基准元素（这里选择第一个元素）\n        pivot = arr[0]\n        # 创建两个列表，一个用于存放比基准小的元素，另一个存放比基准大的元素\n        less_than_pivot = []\n        greater_than_pivot = []\n        for i in range(1, len(arr)):\n            # 如果元素小于基准，放入less_than_pivot列表\n            if arr[i] < pivot:\n                less_than_pivot.append(arr[i])\n            # 否则，放入greater_than_pivot列表\n            else:\n                greater_than_pivot.append(arr[i])\n        # 对两个子列表进行递归排序，然后将结果和基准元素合并\n        return quick_sort(less_than_pivot) + [pivot] + quick_sort(greater_than_pivot)\n\n# 测试代码\narr = [3,6,8,10,1,2,1]\nprint(\"原始数组:\", arr)\nprint(\"排序后的数组:\", quick_sort(arr))\n```\n\n这个快速排序算法首先检查数组的长度，如果长度小于等于1，它就直接返回数组（因为长度为1或0的数组已经是排序好的）。否则，它选择一个基准元素（这里选择第一个元素），并将数组分为两部分：一部分是小于基准的所有元素，另一部分是大于基准的所有元素。然后对这两部分递归地应用同样的过程，最后将结果合并在一起。\n","output_type":"stream"}],"execution_count":9}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9088d0ca",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:38.560273Z",
     "iopub.status.busy": "2025-07-25T10:36:38.560073Z",
     "iopub.status.idle": "2025-07-25T10:36:40.452667Z",
     "shell.execute_reply": "2025-07-25T10:36:40.451856Z"
    },
    "papermill": {
     "duration": 1.897505,
     "end_time": "2025-07-25T10:36:40.453838",
     "exception": false,
     "start_time": "2025-07-25T10:36:38.556333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/camel-xiangzi-1/Camel Xiangzi.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac434774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:40.460269Z",
     "iopub.status.busy": "2025-07-25T10:36:40.459583Z",
     "iopub.status.idle": "2025-07-25T10:36:46.685066Z",
     "shell.execute_reply": "2025-07-25T10:36:46.684447Z"
    },
    "papermill": {
     "duration": 6.229722,
     "end_time": "2025-07-25T10:36:46.686338",
     "exception": false,
     "start_time": "2025-07-25T10:36:40.456616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd7db9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.692467Z",
     "iopub.status.busy": "2025-07-25T10:36:46.691892Z",
     "iopub.status.idle": "2025-07-25T10:36:46.697930Z",
     "shell.execute_reply": "2025-07-25T10:36:46.697362Z"
    },
    "papermill": {
     "duration": 0.009946,
     "end_time": "2025-07-25T10:36:46.698915",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.688969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "class Head(nn.Module):\n",
    " \"\"\" one head of self-attention \"\"\"\n",
    " def __init__(self, n_embd, head_size, dropout):\n",
    "     super().__init__()\n",
    "     self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "     self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "     self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "     self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "     self.dropout = nn.Dropout(dropout)\n",
    " def forward(self, x):\n",
    "     B,T,C = x.shape\n",
    "     k = self.key(x) # (B,T,C)\n",
    "     q = self.query(x) # (B,T,C)\n",
    "     # ⾃注意⼒计算(相关性)\n",
    "     wei = q @ k.transpose(-2,-1) * C ** -0.5 # (B,T,C) @ (B,C,T) -> (B,T,T)\n",
    "     wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B,T,T)\n",
    "     wei = F.softmax(wei, dim=-1) # (B,T,T)\n",
    "     wei = self.dropout(wei)\n",
    "     # value的加权运算\n",
    "     v = self.value(x) # (B,T,C)\n",
    "     out = wei @ v # (B,T,T) @ (B,T,C) - > (B,T,C)\n",
    "     return out\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28e48e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.704100Z",
     "iopub.status.busy": "2025-07-25T10:36:46.703915Z",
     "iopub.status.idle": "2025-07-25T10:36:46.708532Z",
     "shell.execute_reply": "2025-07-25T10:36:46.707985Z"
    },
    "papermill": {
     "duration": 0.008309,
     "end_time": "2025-07-25T10:36:46.709512",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.701203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###多头机制\n",
    "\"\"\"\n",
    "多头机制\n",
    "\"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    " \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    " def __init__(self, num_heads, n_embd, head_size,dropout):\n",
    "     super().__init__()\n",
    "     self.heads = nn.ModuleList([Head(n_embd, head_size,dropout) for _ in range(num_heads)])\n",
    "     self.proj = nn.Linear(n_embd, n_embd)\n",
    "     self.dropout = nn.Dropout(dropout)\n",
    " def forward(self, x):\n",
    "     out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "     out = self.dropout(self.proj(out))\n",
    "     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fa6039d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.714925Z",
     "iopub.status.busy": "2025-07-25T10:36:46.714288Z",
     "iopub.status.idle": "2025-07-25T10:36:46.718179Z",
     "shell.execute_reply": "2025-07-25T10:36:46.717707Z"
    },
    "papermill": {
     "duration": 0.007449,
     "end_time": "2025-07-25T10:36:46.719158",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.711709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##前馈层\n",
    "class FeedFoward(nn.Module):\n",
    " def __init__(self, n_embd, dropout):\n",
    "     super().__init__()\n",
    "     self.net = nn.Sequential(\n",
    "     nn.Linear(n_embd, 4 * n_embd),\n",
    "     nn.ReLU(),\n",
    "     nn.Linear(4 * n_embd, n_embd),\n",
    "     nn.Dropout(dropout),\n",
    "\n",
    "     )\n",
    " def forward(self, x):\n",
    "     return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1357cd14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.724368Z",
     "iopub.status.busy": "2025-07-25T10:36:46.723998Z",
     "iopub.status.idle": "2025-07-25T10:36:46.728344Z",
     "shell.execute_reply": "2025-07-25T10:36:46.727825Z"
    },
    "papermill": {
     "duration": 0.007952,
     "end_time": "2025-07-25T10:36:46.729271",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.721319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###self-attention模块\n",
    "class Block(nn.Module):\n",
    " def __init__(self, n_embd, n_head):\n",
    "     super().__init__()\n",
    "    \n",
    "     head_size = n_embd // n_head\n",
    "     self.sa = MultiHeadAttention(n_head, n_embd, head_size,dropout)\n",
    "     self.ffwd = FeedFoward(n_embd,dropout)\n",
    "     self.ln1 = nn.LayerNorm(n_embd)\n",
    "     self.ln2 = nn.LayerNorm(n_embd)\n",
    " def forward(self, x):\n",
    "     x = x + self.sa(self.ln1(x)) # 残差连接\n",
    "     x = x + self.ffwd(self.ln2(x)) # 残差连接\n",
    "     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef52412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.734390Z",
     "iopub.status.busy": "2025-07-25T10:36:46.734035Z",
     "iopub.status.idle": "2025-07-25T10:36:46.740786Z",
     "shell.execute_reply": "2025-07-25T10:36:46.740274Z"
    },
    "papermill": {
     "duration": 0.01035,
     "end_time": "2025-07-25T10:36:46.741747",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.731397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    " def __init__(self):\n",
    "     super().__init__()\n",
    "     # 每个token直接输出的logits值作为下⼀个token的映射\n",
    "     self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "     self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "     self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "     self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "     self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    " def forward(self, idx, targets=None):\n",
    "     B, T = idx.shape\n",
    "     # idx和target都是维度为 (B,T) 的整型tensor\n",
    "     tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "     pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "     x = tok_emb + pos_emb # (B, T, C)\n",
    "     x = self.blocks(x) # (B,T,C)\n",
    "     x = self.ln_f(x) # (B,T,C)\n",
    "     logits = self.lm_head(x) # (B,T, vocab_size)\n",
    "     if targets is None:\n",
    "         loss = None\n",
    "     else:\n",
    "         B, T, C = logits.shape\n",
    "         logits = logits.reshape(B * T, C)\n",
    "         targets = targets.reshape(B * T)\n",
    "         loss = F.cross_entropy(logits, targets)\n",
    "     return logits, loss\n",
    " def generate(self, idx, max_new_tokens):\n",
    "     # idx指当前语料集(B,T)中的索引\n",
    "     for _ in range(max_new_tokens):\n",
    "         # 限定索引列的取值范围\n",
    "         idx_cond = idx[:, -block_size:]\n",
    "         # 推理\n",
    "         logits, loss = self(idx_cond)\n",
    "         # 只提取最后⼀个时间步的结果\n",
    "         logits = logits[:, -1, :] # (B,T)\n",
    "         # 通过softmax转换为概率值\n",
    "         probs = F.softmax(logits, dim=-1) # (B,T)\n",
    "         # 随机采样\n",
    "         idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "         # 把采样的索引追加在当前解码序列末尾\n",
    "         idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "     return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e8a818e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.746808Z",
     "iopub.status.busy": "2025-07-25T10:36:46.746601Z",
     "iopub.status.idle": "2025-07-25T10:36:46.750893Z",
     "shell.execute_reply": "2025-07-25T10:36:46.750229Z"
    },
    "papermill": {
     "duration": 0.008019,
     "end_time": "2025-07-25T10:36:46.751953",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.743934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batch(split): ##split区别是训练和验证数据集\n",
    "    ##选择训练或者验证数据集\n",
    "    data=train_data if split=='train' else val_data\n",
    "    ##动态从数据集中选择一个位置索引\n",
    "    ix=torch.randint(len(data)-block_size-1,(batch_size,)) ##随机生成位置索引，向后截取block_size个字符作为训练\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f4d9502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.757383Z",
     "iopub.status.busy": "2025-07-25T10:36:46.756827Z",
     "iopub.status.idle": "2025-07-25T10:36:46.761076Z",
     "shell.execute_reply": "2025-07-25T10:36:46.760393Z"
    },
    "papermill": {
     "duration": 0.007971,
     "end_time": "2025-07-25T10:36:46.762187",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.754216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out={}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses=torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y=get_batch(split)\n",
    "            X.to(device),Y.to(device)\n",
    "            logits,loss=model(X,Y)\n",
    "            losses[k]=loss.item()\n",
    "        out[split]=losses.mean()\n",
    "    model.train()\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca66792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.767344Z",
     "iopub.status.busy": "2025-07-25T10:36:46.766951Z",
     "iopub.status.idle": "2025-07-25T10:36:46.893850Z",
     "shell.execute_reply": "2025-07-25T10:36:46.893260Z"
    },
    "papermill": {
     "duration": 0.130904,
     "end_time": "2025-07-25T10:36:46.895226",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.764322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###读取数据\n",
    "file_name='/kaggle/input/camel-xiangzi-1/Camel Xiangzi.txt'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    text=f.read()\n",
    "\n",
    "###词典 编码器(函数），解码器（函数）\n",
    "chars=sorted(list(set(text)))\n",
    "\n",
    "\n",
    "stoi={ ch:i for  i,ch in enumerate(chars)}\n",
    "itos={ i:ch for  i,ch in enumerate(chars)}\n",
    "vocab_size=len(stoi)\n",
    "\n",
    "encode=lambda s:  [ stoi[c] for c in s ]\n",
    "decode=lambda l:  ''.join( itos[i] for i in l )\n",
    "\n",
    "\n",
    "##文本转换 token index \n",
    "data=torch.tensor(encode(text),dtype=torch.long)\n",
    "\n",
    "#拆分数据集\n",
    "n=int(len(data)*.9)\n",
    "\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe0b820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T10:36:46.900411Z",
     "iopub.status.busy": "2025-07-25T10:36:46.900227Z",
     "iopub.status.idle": "2025-07-25T11:35:13.156230Z",
     "shell.execute_reply": "2025-07-25T11:35:13.155529Z"
    },
    "papermill": {
     "duration": 3506.260331,
     "end_time": "2025-07-25T11:35:13.157909",
     "exception": false,
     "start_time": "2025-07-25T10:36:46.897578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 8.0297, val loss 8.0266\n",
      "step 500: train loss 3.4999, val loss 4.7579\n",
      "step 1000: train loss 1.9560, val loss 5.2296\n",
      "step 1500: train loss 0.5974, val loss 6.2790\n",
      "step 2000: train loss 0.2157, val loss 7.2481\n",
      "step 2500: train loss 0.1419, val loss 7.8445\n",
      "step 3000: train loss 0.1120, val loss 8.2794\n",
      "step 3500: train loss 0.0961, val loss 8.6712\n",
      "step 4000: train loss 0.0871, val loss 8.9072\n",
      "step 4500: train loss 0.0793, val loss 9.1600\n"
     ]
    }
   ],
   "source": [
    "##模型训练\n",
    "batch_size = 64\n",
    "block_size = 256\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# weight_decay=1e-4\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# 创建⼀个梯度更新的优化器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_interval == 0:\n",
    "     losses = estimate_loss()\n",
    "     print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "     # 批次样本\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd72cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-25T11:35:13.165589Z",
     "iopub.status.busy": "2025-07-25T11:35:13.165115Z",
     "iopub.status.idle": "2025-07-25T11:35:23.316329Z",
     "shell.execute_reply": "2025-07-25T11:35:23.315520Z"
    },
    "papermill": {
     "duration": 10.156218,
     "end_time": "2025-07-25T11:35:23.317546",
     "exception": false,
     "start_time": "2025-07-25T11:35:13.161328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "　　“动！”她往棚里一指——祥子正弯着腰扫地呢，一边往屋里走。\n",
      "\n",
      "　　“怕什么，”她在外面坐着呢，立着呢，脸上可是手的将瓦片血，怪粉红的唇。“我告诉你别动也别楞和我受了，就得也接着。”\n",
      "\n",
      "　　“这就行！”祥子手心中也凉了些钱洒在香烟的手接过来，穷恶心，在极有力。“这么晚的甩手哆嗦了！”\n",
      "\n",
      "　　“先生，”祥子也没出声。\n",
      "\n",
      "　　“出了我，我来拿多拿多少拿一个小马儿去，准知道你泥，连个响嗝，还是乖得剥下来的东西。你是不傻兄弟，会落座儿，就是放心了他的，活该保不但是拉车，他会出主意祥子——虽然不会欢群子，不是欺骗他钉子。有祥子这个是有同样的车夫，他娶亲自己。二来是属于年轻气比的人。老头子汉不知道这个热心的车夫，这个营“改了主儿”上这个老主意，可是只要脸见一个小伙子这样的人。祥子不象是拴婿的去听，他不象个拉车的那样最好的车，也不自己的车夫。\n",
      "\n",
      "　　再说到了，祥子的光明白着一辆车。夏常在思想。这辆车上，可是他时时候，两天这为什么这样想过妇就一些。关心中一些，他似乎不敢再受拴来几天的混过去而落已的疼痛的事；有时候，他又想起虎妞那些小福子，仿佛没有看看地上骆驼——自在树已很快的在一上，他眼中爬在黑暗\n"
     ]
    }
   ],
   "source": [
    "# 通过模型⽣成\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(idx, max_new_tokens=500)[0].tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7842292,
     "sourceId": 12432713,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3533.302502,
   "end_time": "2025-07-25T11:35:26.367856",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-25T10:36:33.065354",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN神经网络模型创建 & 模型训练 & 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.v2 import ToTensor     # 转换图像数据为张量\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader  # 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "LR = 1e-3\n",
    "MAX_EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集加载\n",
    "train_dataset = FashionMNIST(root='./fashion_data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = FashionMNIST(root='./fashion_data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# 将数据集包装成一个可迭代的对象，方便批量加载数据\n",
    "trian_data_batch_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)  # shuffle=True表示打乱数据\n",
    "test_data_batch_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将多个层按顺序组合在一起，创建一个NN神经网络模型\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss: 2.2921106815338135\n",
      "Epoch:1 Loss: 2.2457001209259033\n",
      "Epoch:2 Loss: 2.223040819168091\n",
      "Epoch:3 Loss: 2.189197063446045\n",
      "Epoch:4 Loss: 2.1689929962158203\n",
      "Epoch:5 Loss: 2.1303155422210693\n",
      "Epoch:6 Loss: 2.0892035961151123\n",
      "Epoch:7 Loss: 2.0608928203582764\n",
      "Epoch:8 Loss: 2.021317720413208\n",
      "Epoch:9 Loss: 1.9931696653366089\n",
      "Epoch:10 Loss: 1.939702033996582\n",
      "Epoch:11 Loss: 1.91756010055542\n",
      "Epoch:12 Loss: 1.855538249015808\n",
      "Epoch:13 Loss: 1.8383941650390625\n",
      "Epoch:14 Loss: 1.803165316581726\n",
      "Epoch:15 Loss: 1.7507432699203491\n",
      "Epoch:16 Loss: 1.6898185014724731\n",
      "Epoch:17 Loss: 1.6940175294876099\n",
      "Epoch:18 Loss: 1.612195372581482\n",
      "Epoch:19 Loss: 1.5848363637924194\n"
     ]
    }
   ],
   "source": [
    "# 神经网络模型训练\n",
    "\n",
    "### 神经网络模型的损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "\n",
    "### 创建一个SGD优化器，用于管理模型参数的优化过程\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)  # SGD（随机梯度下降）是GD梯度下降算法的一种变体，是PyTorch 深度学习中最常用的优化算法之一。 第一个参数是需要优化的模型参数，通常是通过 model.parameters() 获取\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    #### 批量加载训练数据\n",
    "    for datas, targets in trian_data_batch_loader:\n",
    "        ##### 前向运算\n",
    "        outputs = model(datas.reshape(-1, 784))\n",
    "        ##### 计算损失\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        ##### 反向传播\n",
    "        optimizer.zero_grad()  # 清空模型参数的梯度（清空模型参数的 .grad 属性）\n",
    "        loss.backward()     # 计算梯度，计算出的梯度会被保存到模型参数的 .grad 属性中\n",
    "        optimizer.step()    # 根据计算出的梯度（模型参数的 .grad 属性）更新模型参数\n",
    "\n",
    "    print(f'Epoch:{epoch} Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.96000000000001%\n"
     ]
    }
   ],
   "source": [
    "# 模型验证\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    for datas, real_labels in test_data_batch_loader:\n",
    "        outputs = model(datas.reshape(-1, 784))\n",
    "        _, predict_labels= torch.max(outputs, 1)  # 返回 1（列）维度的最大值及其索引\n",
    "        total += real_labels.size(0)  # size(0) 等效 shape[0]\n",
    "        correct += (predict_labels == real_labels).sum().item()   # item()作用是将单元素张量中的值转换为标准的 Python 标量\n",
    "\n",
    "print(f'Accuracy: {correct/total*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "tensor([3, 1, 7, 5, 7, 2, 9, 2, 8, 9, 1, 9, 1, 3, 1, 7])\n",
      "tensor([3, 2, 7, 5, 8, 4, 5, 6, 8, 9, 1, 9, 1, 8, 1, 5])\n",
      "torch.Size([16, 10])\n",
      "tensor([[ 6.1565e-01,  8.4695e-01, -1.8687e-01,  1.0305e+00,  1.6089e-01,\n",
      "         -5.5101e-01,  1.4671e-01, -8.6142e-01, -5.2219e-01, -1.0906e+00],\n",
      "        [ 2.3099e-01,  3.0338e-01,  1.3966e-01,  2.6335e-01,  2.3699e-01,\n",
      "         -3.0825e-01,  2.1673e-01, -4.2621e-01, -2.0000e-01, -4.9406e-01],\n",
      "        [-1.1875e+00, -6.5277e-01, -4.0597e-01, -8.5361e-01, -5.4064e-01,\n",
      "          1.3349e+00, -4.7986e-01,  1.6743e+00,  7.6120e-01,  9.7126e-01],\n",
      "        [-6.3345e-01, -4.7233e-01, -2.3001e-01, -5.6015e-01, -3.5503e-01,\n",
      "          8.8611e-01, -2.5039e-01,  6.1920e-01,  4.2348e-01,  8.3075e-01],\n",
      "        [-8.4474e-01, -8.6412e-01, -1.9029e-02, -9.7825e-01, -1.9212e-01,\n",
      "          9.5022e-01, -2.0681e-01,  1.1285e+00,  1.0014e+00,  9.1366e-01],\n",
      "        [ 3.9304e-01, -8.1164e-02,  6.5074e-01,  8.3177e-02,  6.3914e-01,\n",
      "         -5.4854e-01,  6.2236e-01, -6.8578e-01, -1.8961e-02, -7.0084e-01],\n",
      "        [-3.0334e-01, -5.7430e-01,  1.5471e-01, -5.5347e-01, -1.3552e-01,\n",
      "          5.0487e-01, -6.4108e-04,  1.2169e-01,  3.0078e-01,  8.2579e-01],\n",
      "        [ 4.0959e-01, -1.3193e-01,  5.6757e-01,  4.9649e-03,  4.5393e-01,\n",
      "         -4.2418e-01,  5.6510e-01, -4.9004e-01,  6.1236e-02, -6.1752e-01],\n",
      "        [ 4.7549e-02, -3.5046e-01,  1.2857e-01, -6.5727e-02,  2.5290e-01,\n",
      "         -5.1402e-02,  1.7278e-01, -1.5905e-01,  5.5408e-01, -1.8042e-01],\n",
      "        [-1.0163e+00, -1.0261e+00, -1.2048e-01, -1.2309e+00, -4.4073e-01,\n",
      "          1.1016e+00, -5.1382e-01,  1.0289e+00,  9.9617e-01,  1.8924e+00],\n",
      "        [ 3.9594e-01,  1.4288e+00, -2.8889e-01,  1.1355e+00,  1.1980e-01,\n",
      "         -5.4730e-01,  8.7681e-02, -8.5897e-01, -9.4793e-01, -1.1635e+00],\n",
      "        [-9.5503e-01, -9.5949e-01, -8.5044e-02, -1.2063e+00, -3.8182e-01,\n",
      "          1.0145e+00, -4.6520e-01,  9.3968e-01,  9.4085e-01,  1.8464e+00],\n",
      "        [ 1.3472e-01,  9.5080e-01, -2.3957e-01,  7.4504e-01,  8.7768e-03,\n",
      "         -1.4684e-01,  4.4774e-02, -4.0910e-01, -6.6370e-01, -7.9884e-01],\n",
      "        [ 3.6919e-01,  1.7613e-01, -1.6358e-01,  4.5106e-01,  9.3704e-02,\n",
      "         -1.5073e-01,  1.2974e-01, -4.9305e-01,  5.6353e-02, -5.2304e-01],\n",
      "        [ 3.1097e-01,  1.3530e+00, -3.3830e-01,  1.1321e+00,  9.1324e-02,\n",
      "         -4.7867e-01,  2.8730e-02, -8.0207e-01, -9.3350e-01, -1.1066e+00],\n",
      "        [-8.3057e-01, -4.3683e-01, -2.2691e-01, -5.8853e-01, -3.3296e-01,\n",
      "          9.2296e-01, -2.5577e-01,  1.0289e+00,  4.6787e-01,  6.6616e-01]])\n"
     ]
    }
   ],
   "source": [
    "# 数据观察\n",
    "print(predict_labels.shape)\n",
    "print(predict_labels)\n",
    "print(real_labels)\n",
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3128",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
